---
- name: "namespace"
  kubernetes.core.k8s:
    state: "present"
    kubeconfig: "{{ kubeconfig }}"
    definition:
      apiVersion: "v1"
      kind: "Namespace"
      metadata:
        name: "{{ namespace }}"

- name: "query if the postgres cluster already exists"
  kubernetes.core.k8s_info:
    kubeconfig: "{{ kubeconfig }}"
    namespace: "{{ namespace }}"
    api_version: "acid.zalan.do/v1"
    kind: "postgresql"
    name: "{{ pg_team_id }}-{{ pg_instance_name }}"
  register: "pg_query"

- name: "do we deploy a new cluster?"
  set_fact: 
    pg_new_cluster: "{{ (pg_query.resources | length) == 0 }}"

- name: "s3 backup target secret"
  when: "pg_backup"
  kubernetes.core.k8s:
    state: "{{ component_state }}"
    kubeconfig: "{{ kubeconfig }}"
    namespace: "{{ namespace }}"
    definition:
      apiVersion: v1
      kind: Secret
      metadata:
        name: "{{ pg_team_id }}-{{ pg_instance_name }}-s3-backup"
      type: Opaque
      data:
        s3_access_key: "{{ pg_s3_access_key | b64encode }}"
        s3_secret_key: "{{ pg_s3_secret_key | b64encode }}"    

- name: "s3 clone source secret"
  when: "pg_clone"
  kubernetes.core.k8s:
    state: "{{ component_state }}"
    kubeconfig: "{{ kubeconfig }}"
    namespace: "{{ namespace }}"
    definition:
      apiVersion: v1
      kind: Secret
      metadata:
        name: "{{ pg_team_id }}-{{ pg_instance_name }}-s3-clone"
      type: Opaque
      data:
        s3_access_key: "{{ pg_clone_s3_access_key | b64encode }}"
        s3_secret_key: "{{ pg_clone_s3_secret_key | b64encode }}"

- name: "query running postgres pods"
  when: "pg_backup"
  kubernetes.core.k8s_info:
    kubeconfig: "{{ kubeconfig }}"
    namespace: "{{ namespace }}"
    api_version: "v1"
    kind: "Pod"
    label_selectors:
      - "cluster-name = {{ pg_team_id }}-{{ pg_instance_name }}"
  register: "pg_pod_query"

- name: "update backup s3 access keys in running pods"
  when: "pg_backup"
  kubernetes.core.k8s_cp:
    kubeconfig: "{{ kubeconfig }}"
    namespace: "{{ namespace }}"
    remote_path: "/home/postgres/etc/wal-e.d/env/AWS_ACCESS_KEY_ID"
    content: "{{ pg_s3_access_key }}"
    pod: "{{ item.metadata.name }}"
  loop: "{{ pg_pod_query.resources }}"
  loop_control:
    label: "{{ item.metadata.name }}"

- name: "update backup s3 secret keys in running pods"
  when: "pg_backup"
  kubernetes.core.k8s_cp:
    kubeconfig: "{{ kubeconfig }}"
    namespace: "{{ namespace }}"
    remote_path: "/home/postgres/etc/wal-e.d/env/AWS_SECRET_ACCESS_KEY"
    content: "{{ pg_s3_secret_key }}"
    pod: "{{ item.metadata.name }}"
  loop: "{{ pg_pod_query.resources }}"
  loop_control:
    label: "{{ item.metadata.name }}"

- name: "check if clone source is present"
  when: "pg_clone"
  amazon.aws.aws_s3:
    s3_url: "{{ pg_clone_s3_endpoint }}"
    aws_access_key: "{{ pg_clone_s3_access_key }}"
    aws_secret_key: "{{ pg_clone_s3_secret_key }}"
    bucket: "{{ pg_clone_s3_bucket }}"
    region: "{{ pg_clone_s3_region }}"
    mode: "list"
    prefix: "{{ pg_clone_full_prefix }}"
  register: "s3_clone_target_list"
  until: "s3_clone_target_list is not failed"
  retries: 10
  delay: 5

- name: "set source exists fact"
  ansible.builtin.set_fact:
    pg_clone_source_exists: "{{ false if not pg_clone else s3_clone_target_list.s3_keys | length > 0 }}"

- name: "clone only if clone source is present"
  ansible.builtin.set_fact: 
    pg_do_clone: "{{ pg_clone and pg_clone_source_exists }}"

- name: "check if backup target is present"
  when: "pg_backup"
  amazon.aws.aws_s3:
    s3_url: "{{ pg_s3_endpoint }}"
    aws_access_key: "{{ pg_s3_access_key }}"
    aws_secret_key: "{{ pg_s3_secret_key }}"
    bucket: "{{ pg_s3_bucket }}"
    region: "{{ pg_s3_region }}"
    mode: "list"
    prefix: "{{ pg_backup_full_prefix }}"
  register: "s3_backup_target_list"

- name: "set backup exists fact"
  ansible.builtin.set_fact:
    pg_backup_target_exists: "{{ false if not pg_backup else s3_backup_target_list.s3_keys | length > 0 }}"

- name: "stop if we are going to overwrite an existing backup with a new db cluster"
  ansible.builtin.assert:
    # we can go on when:
    #  - we are not creating an new cluster
    #  - or we create a new cluster but there is no backup in the target
    #  - or we create a new cluster and there is a backup in the target
    #    but we are cloning from the same location
    that: "(not pg_new_cluster) or
           (not pg_backup_target_exists) or
           (pg_clone and pg_backup_full_path == pg_clone_full_path)"
    fail_msg: "Stopping here to avoid a backup overwrite:
      There is already a backup in 's3://{{ pg_backup_full_path }}' that we are not clone from."
